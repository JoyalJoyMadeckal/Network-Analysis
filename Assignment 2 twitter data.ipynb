{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9131bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required libraries\n",
    "import nltk\n",
    "import math\n",
    "import json\n",
    "import string\n",
    "import tweepy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyLDAvis.sklearn\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Setting the size of plots generated.\n",
    "sns.set(rc={'figure.figsize':(17,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf58fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for initialing the twitter API client\n",
    "def twitterClient():\n",
    "    \"\"\"\n",
    "        Setup Twitter API client.\n",
    "\n",
    "        @returns: tweepy.API object\n",
    "    \"\"\"\n",
    "\n",
    "    bearerToken = \"AAAAAAAAAAAAAAAAAAAAAEhYfgEAAAAAvYoi7EZZYbm6Q%2Bdewk3%2FwM8z9Ng%3DLwZB7gAIfXDGcqq44tFx76vqufvFkuelNdSn7xmDXTnv7h2cGZ\"\n",
    "    client = tweepy.Client(bearerToken)\n",
    "\n",
    "    return client\n",
    "\n",
    "# Fields to be retrieved\n",
    "response_fields = ['created_at',\"entities\", \"text\", \"lang\", \"public_metrics\", 'geo']\n",
    "\n",
    "# Initialising the twitter client\n",
    "client = twitterClient()\n",
    "\n",
    "# # Using paginator retrieving all the required tweets. We will be receiving all the tweets from the last 7 days\n",
    "# # tweets = tweepy.Paginator(client.get_users_tweets, id=client.get_user(username=\"trussliz\").data.id, max_results=100).flatten()\n",
    "tweets = tweepy.Paginator(client.search_recent_tweets, query=\"#liztruss\", tweet_fields = response_fields, max_results=100).flatten()\n",
    "\n",
    "# # Converting the tweets to a list object\n",
    "# tweets = list(tweets)\n",
    "\n",
    "tweets_dict_list = []\n",
    "\n",
    "# # Mapping the data retrieved into a list of dictionaries.\n",
    "for tweet in tweets:\n",
    "    tweet_obj = {\n",
    "        \"id\": tweet['id'],\n",
    "        \"text\": tweet.get(\"text\"),\n",
    "        \"time\": str(tweet.get(\"created_at\")),\n",
    "        \"hastags\": [hastag['tag'].lower() for hastag in tweet.get(\"entities\").get(\"hashtags\")] if tweet.get(\"entities\") and tweet.get(\"entities\").get(\"hashtags\") else None,\n",
    "        \"mentions\": [mention['username'].lower() for mention in tweet.get(\"entities\").get(\"mentions\")] if tweet.get(\"entities\") and tweet.get(\"entities\").get(\"mentions\") else None,\n",
    "        \"language\": tweet.get(\"lang\").strip(),\n",
    "        \"retweet count\": tweet.get(\"public_metrics\").get(\"retweet_count\"),\n",
    "        \"like_count\": tweet.get(\"public_metrics\").get(\"like_count\"),\n",
    "        \"country\": tweet.get('geo') if tweet.get('geo') else None\n",
    "    }\n",
    "    tweets_dict_list.append(tweet_obj)\n",
    "    \n",
    "# # # # Creation of the object to be written to the file\n",
    "tweets_data_as_dict = {'data': tweets_dict_list}\n",
    "    \n",
    "# # # # Dumping the json data to the file\n",
    "with open(\"COSC2671-assign1-s3860476.json\", 'w', encoding=\"utf-8\") as data:\n",
    "    json.dump(tweets_data_as_dict, data, indent = 6)\n",
    "\n",
    "# tweets_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0437816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Paginator.flatten at 0x0000022A26F73B30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524ced2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc6d330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    print(tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c289402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tweet id=1580135920748986369 text='RT @riotgrandma72: ðŸ˜±Today, friends, your wibbly little pensioner will be joining @snb19692 and friends at Westminster to give the unmandateâ€¦'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695dc87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
